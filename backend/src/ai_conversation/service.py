"""
OpenAI service for AI conversation functionality

Handles communication with Azure OpenAI API for charity sponsorship matching.
"""

import asyncio
import json
import re
import traceback
from typing import Optional, Dict, Any, List

from openai import OpenAI
from fastapi import HTTPException
from sqlalchemy.orm import Session

# You will need to import your ConversationHistory model and the browse tool
# from where they are defined in your project.
# from ..conversations.models import ConversationHistory 
# from ..core.browser import browse # Assuming you have a browser tool

from ..core.config import get_settings
from ..companies.service import CompanyService
from .location_service import get_canonical_location_from_text

# Language detection helper (use langdetect if installed)
try:
    from langdetect import detect as _detect_lang
except ImportError:  # Fallback ‚Äì default to Russian
    def _detect_lang(text: str) -> str:  # type: ignore
        return "ru"


class OpenAIService:
    """Service for handling OpenAI API interactions with database integration"""
    
    def __init__(self):
        """Initializes the service and sets up the OpenAI client."""
        self.settings = get_settings()
        
        # Use the SYNCHRONOUS OpenAI client
        self.client = OpenAI(
            api_key=self.settings.OPENAI_API_KEY,
        )

    def _parse_user_intent_with_history(self, history: List[Dict[str, str]]) -> Dict[str, Any]:
        """
        Uses OpenAI to parse the latest user message in Russian, using the full conversation history for context.
        """
        
        # --- DEBUG: Add extensive logging for pagination troubleshooting ---
        print(f"üîç [INTENT_PARSER] Analyzing history length: {len(history)}")
        if history:
            print(f"üîç [INTENT_PARSER] Last user message: {history[-1].get('content', 'N/A')[:100]}...")
            
            # Find the most recent search context for debugging
            user_messages = [msg for msg in history if msg.get('role') == 'user']
            print(f"üîç [INTENT_PARSER] Total user messages in history: {len(user_messages)}")
            
            # Look for previous search requests
            search_keywords = ['–Ω–∞–π–¥–∏', 'find', '–∫–æ–º–ø–∞–Ω–∏', 'companies', '–ø–æ–∏—Å–∫']
            for i, msg in enumerate(reversed(user_messages)):
                content = msg.get('content', '').lower()
                if any(keyword in content for keyword in search_keywords):
                    print(f"üîç [INTENT_PARSER] Found previous search at position -{i}: {content[:100]}...")
                    break
        
        # --- FALLBACK LOGIC: Pattern-based continuation detection ---
        fallback_result = self._detect_continuation_fallback(history)
        if fallback_result:
            print(f"üîÑ [INTENT_PARSER] Fallback detection succeeded, using fallback result")
            return fallback_result
        
        # --- PROMPT FIX FOR MAXIMUM CONTEXT RELIABILITY ---
        system_prompt = """
        –¢—ã ‚Äî –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ 'Ayala'. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ü–û–°–õ–ï–î–ù–ï–ï —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∏—Å–ø–æ–ª—å–∑—É—è –ò–°–¢–û–†–ò–Æ –î–ò–ê–õ–û–ì–ê –∫–∞–∫ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, —á—Ç–æ–±—ã –∏–∑–≤–ª–µ—á—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞.

        –¢—ã –î–û–õ–ñ–ï–ù –≤—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞—Ç—å –¢–û–õ–¨–ö–û –æ–¥–Ω–∏–º –≤–∞–ª–∏–¥–Ω—ã–º JSON-–æ–±—ä–µ–∫—Ç–æ–º.

        **–ö–õ–Æ–ß–ï–í–û–ï –ü–†–ê–í–ò–õ–û: –ö–û–ù–¢–ï–ö–°–¢ –ò–ó –ò–°–¢–û–†–ò–ò**
        –¢–≤–æ—è –≥–ª–∞–≤–Ω–∞—è –∑–∞–¥–∞—á–∞ ‚Äî –±–µ–∑–æ—à–∏–±–æ—á–Ω–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞.
        1.  **–ù–∞–π–¥–∏ "–±–∞–∑–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç":** –í –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞ –Ω–∞–π–¥–∏ **—Å–∞–º—ã–π –ø–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–ø—Ä–æ—Å –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è**, –≤ –∫–æ—Ç–æ—Ä–æ–º –±—ã–ª–∏ —è–≤–Ω–æ —É–∫–∞–∑–∞–Ω—ã –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞ (`location`, `activity_keywords`). –≠—Ç–æ –∏ –µ—Å—Ç—å —Ç–≤–æ–π "–±–∞–∑–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç".
        2.  **–ò—Å–ø–æ–ª—å–∑—É–π "–±–∞–∑–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç":** –ï—Å–ª–∏ —Ç–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ‚Äî —ç—Ç–æ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –ø–æ–∏—Å–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–¥–∞–π –µ—â–µ", "—Å–ª–µ–¥—É—é—â–∏–µ", "Find another 15 companies", "Give me more", "Show me more companies"), —Ç—ã –û–ë–Ø–ó–ê–ù –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `location` –∏ `activity_keywords` –∏–∑ "–±–∞–∑–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞".
            - **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ:** –ò–≥–Ω–æ—Ä–∏—Ä—É–π –ª—é–±—ã–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ –Ω–µ—É–¥–∞—á–µ –ø–æ–∏—Å–∫–∞ –∏–ª–∏ —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º —Å–º–µ–Ω–∏—Ç—å –≥–æ—Ä–æ–¥). –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞ –≤—Å–µ–≥–¥–∞ –±–µ—Ä–µ—Ç—Å—è –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ *–∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è*.
        3.  **–û–ø—Ä–µ–¥–µ–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ:** –ï—Å–ª–∏ –≤ —Ç–µ–∫—É—â–µ–º –∑–∞–ø—Ä–æ—Å–µ —É–∫–∞–∑–∞–Ω–æ –Ω–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ ("–¥–∞–π –µ—â–µ 20", "another 15"), –∏—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ. –ï—Å–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ —É–∫–∞–∑–∞–Ω–æ, –≤–æ–∑—å–º–∏ –µ–≥–æ –∏–∑ "–±–∞–∑–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞" –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π 10 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.
        4.  **–£–≤–µ–ª–∏—á—å —Å—Ç—Ä–∞–Ω–∏—Ü—É:** –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞-–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è ("–¥–∞–π –µ—â–µ", "—Å–ª–µ–¥—É—é—â–∏–µ", "more", "another") **—É–≤–µ–ª–∏—á–∏–≤–∞–π `page_number` –Ω–∞ 1**. –î–ª—è –ø–µ—Ä–≤–æ–≥–æ (–∏–ª–∏ –Ω–æ–≤–æ–≥–æ) –ø–æ–∏—Å–∫–∞ `page_number` –≤—Å–µ–≥–¥–∞ 1.

        **–ü–†–ê–í–ò–õ–û –õ–û–ö–ê–õ–ò–ó–ê–¶–ò–ò:**
        - –ï—Å–ª–∏ –≥–æ—Ä–æ–¥ —É–∫–∞–∑–∞–Ω –ª–∞—Ç–∏–Ω–∏—Ü–µ–π (Almaty, Astana), –ø–µ—Ä–µ–≤–µ–¥–∏ –µ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π (–ê–ª–º–∞—Ç—ã, –ê—Å—Ç–∞–Ω–∞).

        **–ö–õ–Æ–ß–ï–í–´–ï –°–õ–û–í–ê –ü–†–û–î–û–õ–ñ–ï–ù–ò–Ø:**
        –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–π —ç—Ç–∏ —Ñ—Ä–∞–∑—ã –∫–∞–∫ –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –ø–æ–∏—Å–∫–∞:
        - –†—É—Å—Å–∫–∏–µ: "–¥–∞–π –µ—â–µ", "–ø–æ–∫–∞–∂–∏ –µ—â–µ", "–Ω–∞–π–¥–∏ –µ—â–µ", "–µ—â–µ X –∫–æ–º–ø–∞–Ω–∏–π", "—Å–ª–µ–¥—É—é—â–∏–µ", "–±–æ–ª—å—à–µ", "–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ", "–ø—Ä–æ–¥–æ–ª–∂–∏"
        - –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ: "give me more", "show me more", "another", "next", "additional", "find more"

        –°—Ç—Ä—É–∫—Ç—É—Ä–∞ JSON:
        {
          "intent": "string",
          "location": "string | null",
          "activity_keywords": ["string"] | null,
          "quantity": "number | null",
          "page_number": "number",
          "reasoning": "string",
          "preliminary_response": "string"
        }

        –û–ø–∏—Å–∞–Ω–∏–µ –ø–æ–ª–µ–π:
        - "intent": "find_companies", "general_question", "unclear".
        - "location": –ì–æ—Ä–æ–¥ –ù–ê –†–£–°–°–ö–û–ú. –ï—Å–ª–∏ –≤ —Ç–µ–∫—É—â–µ–º –∑–∞–ø—Ä–æ—Å–µ –µ–≥–æ –Ω–µ—Ç, **–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ë–ï–†–ò –ò–ó –ò–°–¢–û–†–ò–ò**. –ï—Å–ª–∏ –≤ –∏—Å—Ç–æ—Ä–∏–∏ –Ω–µ—Ç ‚Äî null.
        - "activity_keywords": –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞. –ï—Å–ª–∏ –≤ —Ç–µ–∫—É—â–µ–º –∑–∞–ø—Ä–æ—Å–µ –∏—Ö –Ω–µ—Ç, **–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ë–ï–†–ò –ò–ó –ò–°–¢–û–†–ò–ò**. –ï—Å–ª–∏ –≤ –∏—Å—Ç–æ—Ä–∏–∏ –Ω–µ—Ç ‚Äî null.
        - "quantity": –ß–∏—Å–ª–æ –∫–æ–º–ø–∞–Ω–∏–π. –≠—Ç–æ –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û–ï –ø–æ–ª–µ. –¢—ã –û–ë–Ø–ó–ê–ù –∏–∑–≤–ª–µ—á—å —Ç–æ—á–Ω–æ–µ —á–∏—Å–ª–æ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–∑ "–Ω–∞–π–¥–∏ 30 –∫–æ–º–ø–∞–Ω–∏–π" –∏–∑–≤–ª–µ–∫–∏ 30). –ï—Å–ª–∏ —á–∏—Å–ª–æ –Ω–µ —É–∫–∞–∑–∞–Ω–æ –Ø–í–ù–û, –∏—Å–ø–æ–ª—å–∑—É–π 10. –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π —á–∏—Å–ª–æ, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç.
        - "page_number": –ù–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã. –£–≤–µ–ª–∏—á–∏–≤–∞–π –Ω–∞ 1 –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤-–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–π.
        - "reasoning": –¢–≤–æ–µ –ø–æ—à–∞–≥–æ–≤–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ª–æ–≥–∏–∫–∏.
        - "preliminary_response": –û—Ç–≤–µ—Ç-–∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

        --- –ü–†–ò–ú–ï–†–´ (–ü–û–ö–ê–ó–´–í–ê–Æ–¢ –¢–û–õ–¨–ö–û –§–û–†–ú–ê–¢) ---

        –ü—Ä–∏–º–µ—Ä 1: –ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å
        –ò—Å—Ç–æ—Ä–∏—è: []
        –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: "–ù–∞–π–¥–∏ 15 IT –∫–æ–º–ø–∞–Ω–∏–π –≤ Almaty"
        –û–∂–∏–¥–∞–µ–º—ã–π JSON:
        {
          "intent": "find_companies",
          "location": "–ê–ª–º–∞—Ç—ã",
          "activity_keywords": ["IT"],
          "quantity": 15,
          "page_number": 1,
          "reasoning": "–≠—Ç–æ –ø–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–∫–∞–∑–∞–ª –≥–æ—Ä–æ–¥ 'Almaty', —è –ø–µ—Ä–µ–≤–µ–ª –µ–≥–æ –≤ '–ê–ª–º–∞—Ç—ã'. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ 15, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ 1.",
          "preliminary_response": "–û—Ç–ª–∏—á–Ω–æ! –ò—â—É –¥–ª—è –≤–∞—Å 15 IT-–∫–æ–º–ø–∞–Ω–∏–π –≤ –ê–ª–º–∞—Ç—ã. –û–¥–∏–Ω –º–æ–º–µ–Ω—Ç..."
        }

        –ü—Ä–∏–º–µ—Ä 2: –ü–æ—Å–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—Ä–æ—Å (—Å–∞–º—ã–π –≤–∞–∂–Ω—ã–π –ø—Ä–∏–º–µ—Ä!)
        –ò—Å—Ç–æ—Ä–∏—è: [
          {"role": "user", "content": "–ù–∞–π–¥–∏ 15 IT –∫–æ–º–ø–∞–Ω–∏–π –≤ Almaty"},
          {"role": "assistant", "content": "–û—Ç–ª–∏—á–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏! –Ø –Ω–∞—à–µ–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ 15 –∫–æ–º–ø–∞–Ω–∏—è—Ö..."}
        ]
        –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: "Give me another 15 companies"
        –û–∂–∏–¥–∞–µ–º—ã–π JSON:
        {
          "intent": "find_companies",
          "location": "–ê–ª–º–∞—Ç—ã", 
          "activity_keywords": ["IT"],
          "quantity": 15,
          "page_number": 2,
          "reasoning": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç 'another 15 companies'. –Ø –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª –∏—Å—Ç–æ—Ä–∏—é –∏ –Ω–∞—à–µ–ª –ø—Ä–µ–¥—ã–¥—É—â–∏–π –ø–æ–∏—Å–∫ '–ù–∞–π–¥–∏ 15 IT –∫–æ–º–ø–∞–Ω–∏–π –≤ Almaty'. –Ø –û–ë–Ø–ó–ê–ù –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `location` ('–ê–ª–º–∞—Ç—ã') –∏ `activity_keywords` (['IT']) –∏–∑ —ç—Ç–æ–≥–æ –ø–æ–∏—Å–∫–∞. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ '15' –≤–∑—è—Ç–æ –∏–∑ —Ç–µ–∫—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞. –Ø —É–≤–µ–ª–∏—á–∏–ª –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–æ 2, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ.",
          "preliminary_response": "–ö–æ–Ω–µ—á–Ω–æ! –ò—â—É —Å–ª–µ–¥—É—é—â—É—é –≥—Ä—É–ø–ø—É –∏–∑ 15 IT-–∫–æ–º–ø–∞–Ω–∏–π –≤ –ê–ª–º–∞—Ç—ã. –ü–æ–¥–æ–∂–¥–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞."
        }
        """
        # --- PROMPT FIX ENDS HERE ---
        
        messages_with_context = [{"role": "system", "content": system_prompt}] + history

        try:
            print(f"ü§ñ [INTENT_PARSER] Calling OpenAI with {len(messages_with_context)} messages...")
            
            response = self.client.chat.completions.create(
                model=self.settings.OPENAI_MODEL_NAME, # Use the standard model name
                messages=messages_with_context,
                response_format={"type": "json_object"},
                temperature=0.0
            )
            
            result = json.loads(response.choices[0].message.content)
            
            # --- DEBUG: Log the parsed result ---
            print(f"‚úÖ [INTENT_PARSER] OpenAI response:")
            print(f"   Intent: {result.get('intent')}")
            print(f"   Location: {result.get('location')}")
            print(f"   Activity Keywords: {result.get('activity_keywords')}")
            print(f"   Quantity: {result.get('quantity')}")
            print(f"   Page Number: {result.get('page_number')}")
            print(f"   Reasoning: {result.get('reasoning', '')[:100]}...")
            
            return result
            
        except Exception as e:
            # Enhanced error logging
            print(f"‚ùå Error during OpenAI intent parsing: {e}")
            print(f"üîç History length: {len(history)}")
            print(f"üîç Last user message: {history[-1].get('content', 'N/A') if history else 'No history'}")
            traceback.print_exc()
            
            # Try fallback again if OpenAI fails completely
            print(f"üîÑ [INTENT_PARSER] Trying fallback detection after OpenAI failure...")
            fallback_after_error = self._detect_continuation_fallback(history)
            if fallback_after_error:
                print(f"‚úÖ [INTENT_PARSER] Fallback succeeded after OpenAI error")
                return fallback_after_error
            
            return {
                "intent": "unclear", 
                "location": None,
                "activity_keywords": None,
                "quantity": None,
                "page_number": 1,
                "reasoning": f"–ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑-–∑–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π –æ—à–∏–±–∫–∏: {str(e)}",
                "preliminary_response": "–ò–∑–≤–∏–Ω–∏—Ç–µ, —É –º–µ–Ω—è –≤–æ–∑–Ω–∏–∫–ª–∞ –ø—Ä–æ–±–ª–µ–º–∞ —Å –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π—Ç–µ."
            }

    def _detect_continuation_fallback(self, history: List[Dict[str, str]]) -> Optional[Dict[str, Any]]:
        """
        Fallback method to detect continuation requests using pattern matching.
        This runs when OpenAI parsing might fail or return ambiguous results.
        """
        if not history or len(history) < 2:
            return None
            
        current_message = history[-1].get('content', '').lower().strip()
        print(f"üîÑ [FALLBACK] Analyzing current message: {current_message}")
        
        # Continuation patterns
        continuation_patterns = [
            # English patterns
            r'\b(give\s+me\s+)?(more|another)\b',
            r'\b(show\s+me\s+)?(more|additional)\b',
            r'\bnext\s+\d+\b',
            r'\banother\s+\d+\b',
            # Russian patterns - improved to be more flexible
            r'\b(–µ—â—ë|–µ—â–µ)\s+\d+\b',  # "–µ—â–µ 15" - more flexible
            r'\b(–¥–∞–π|–ø–æ–∫–∞–∂–∏|–Ω–∞–π–¥–∏)\s+.*(–µ—â—ë|–µ—â–µ)\b',  # "–Ω–∞–π–¥–∏ –º–Ω–µ –µ—â–µ" - includes –Ω–∞–π–¥–∏
            r'\b—Å–ª–µ–¥—É—é—â–∏–µ\s+\d+\b',
            r'\b–±–æ–ª—å?—à–µ\s+–∫–æ–º–ø–∞–Ω–∏',
            r'\b–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω\b',
            r'\b–ø—Ä–æ–¥–æ–ª–∂–∏\b',  # "–ø—Ä–æ–¥–æ–ª–∂–∏"
            r'\b–µ—â–µ\s+\d+\s+–∫–æ–º–ø–∞–Ω–∏\b'  # "–µ—â–µ 15 –∫–æ–º–ø–∞–Ω–∏–π"
        ]
        
        is_continuation = any(re.search(pattern, current_message) for pattern in continuation_patterns)
        
        if not is_continuation:
            print(f"üîÑ [FALLBACK] Not a continuation request")
            return None
            
        print(f"üîÑ [FALLBACK] Detected continuation request")
        
        # Extract quantity from current message
        quantity_match = re.search(r'\b(\d+)\b', current_message)
        quantity = int(quantity_match.group(1)) if quantity_match else 10
        
        # Find the most recent search context from user messages
        user_messages = [msg for msg in history if msg.get('role') == 'user']
        
        location = None
        activity_keywords = None
        previous_quantity = 10
        
        # Look for previous search parameters in reverse order
        for msg in reversed(user_messages[:-1]):  # Exclude current message
            content = msg.get('content', '').lower()
            
            # Look for location mentions
            if not location:
                # Common city names
                city_patterns = [
                    (r'\balmaty\b', '–ê–ª–º–∞—Ç—ã'),
                    (r'\b–∞–ª–º–∞—Ç—ã\b', '–ê–ª–º–∞—Ç—ã'),
                    (r'\bastana\b', '–ê—Å—Ç–∞–Ω–∞'),
                    (r'\b–∞—Å—Ç–∞–Ω–∞\b', '–ê—Å—Ç–∞–Ω–∞'),
                    (r'\baktau\b', '–ê–∫—Ç–∞—É'),
                    (r'\b–∞–∫—Ç–∞—É\b', '–ê–∫—Ç–∞—É'),
                    (r'\baktobe\b', '–ê–∫—Ç–æ–±–µ'),
                    (r'\b–∞–∫—Ç–æ–±–µ\b', '–ê–∫—Ç–æ–±–µ')
                ]
                
                for pattern, city in city_patterns:
                    if re.search(pattern, content):
                        location = city
                        break
            
            # Look for activity keywords
            if not activity_keywords and any(kw in content for kw in ['–∫–æ–º–ø–∞–Ω–∏', 'companies', '–Ω–∞–π–¥–∏', 'find']):
                # Extract potential activity keywords
                activity_patterns = [
                    r'\bit\s+–∫–æ–º–ø–∞–Ω–∏', r'\bit\s+companies',
                    r'\b—Ç–µ—Ö–Ω–æ–ª–æ–≥', r'\btechnology',
                    r'\b—Å—Ç—Ä–æ–∏—Ç–µ–ª—å', r'\bconstruction',
                    r'\b—Ç–æ—Ä–≥–æ–≤', r'\btrade'
                ]
                
                for pattern in activity_patterns:
                    if re.search(pattern, content):
                        if 'it' in pattern:
                            activity_keywords = ['IT']
                        elif '—Ç–µ—Ö–Ω–æ–ª–æ–≥' in pattern:
                            activity_keywords = ['—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏']
                        elif '—Å—Ç—Ä–æ–∏—Ç–µ–ª—å' in pattern:
                            activity_keywords = ['—Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ']
                        elif '—Ç–æ—Ä–≥–æ–≤' in pattern:
                            activity_keywords = ['—Ç–æ—Ä–≥–æ–≤–ª—è']
                        break
            
            # Look for previous quantity
            prev_quantity_match = re.search(r'\b(\d+)\b', content)
            if prev_quantity_match:
                previous_quantity = int(prev_quantity_match.group(1))
            
            # If we found location and search intent, we have enough context
            if location and any(kw in content for kw in ['–∫–æ–º–ø–∞–Ω–∏', 'companies', '–Ω–∞–π–¥–∏', 'find']):
                break
        
        if not location:
            print(f"üîÑ [FALLBACK] No location found in history")
            return None
            
        # Count previous continuation requests to determine page number
        page_number = 2  # Start at page 2 for first continuation
        continuation_count = 0
        
        for msg in user_messages[:-1]:
            content = msg.get('content', '').lower()
            if any(re.search(pattern, content) for pattern in continuation_patterns):
                continuation_count += 1
                
        page_number = 2 + continuation_count
        
        print(f"üîÑ [FALLBACK] Detected context:")
        print(f"   location: {location}")
        print(f"   activity_keywords: {activity_keywords}")
        print(f"   quantity: {quantity}")
        print(f"   page_number: {page_number}")
        
        return {
            "intent": "find_companies",
            "location": location,
            "activity_keywords": activity_keywords,
            "quantity": quantity,
            "page_number": page_number,
            "reasoning": f"Fallback detection: Found continuation request with location={location}, quantity={quantity}, page={page_number}",
            "preliminary_response": f"–ö–æ–Ω–µ—á–Ω–æ! –ò—â—É —Å–ª–µ–¥—É—é—â—É—é –≥—Ä—É–ø–ø—É –∏–∑ {quantity} –∫–æ–º–ø–∞–Ω–∏–π –≤ {location}. –ü–æ–¥–æ–∂–¥–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞."
        }

    def _enrich_companies_with_web_search(self, companies: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Enriches company data with information from web searches (website, contacts, tax info).
        """
        # This function can remain synchronous if the 'browse' tool is synchronous
        # If browse is async, this would need to be an async function with asyncio.gather
        # For now, assuming a synchronous web search for simplicity
        
        def search_for_company(company: Dict[str, Any]):
            query = f"–ù–∞–π–¥–∏ —Å–∞–π—Ç –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–º–ø–∞–Ω–∏–∏ '{company['name']}' (–ë–ò–ù: {company['bin']}) –≤ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–µ."
            try:
                # Assuming 'browse' is a synchronous function you have defined elsewhere
                # search_result = browse(query, search_engine="google") 
                # For demonstration, we'll just mock a result
                search_result = f"Mock search result for {company['name']}"
                company["web_search_summary"] = search_result
            except Exception as e:
                company["web_search_summary"] = f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –≤–µ–±-–ø–æ–∏—Å–∫: {e}"
            return company

        enriched_companies = [search_for_company(c) for c in companies]
        return enriched_companies

    @staticmethod
    def _get_message_language(history: List[Dict[str, str]]) -> str:
        """Detect the language of the last user message (returns 'en', 'ru', 'kk')."""
        for msg in reversed(history):
            if msg.get("role") == "user":
                try:
                    lang = _detect_lang(msg.get("content", ""))
                    return lang.lower()  # langdetect returns e.g., 'en', 'ru', 'kk'
                except Exception:
                    return "ru" # Default
        return "ru"

    def _generate_summary_response(self, history: List[Dict[str, str]], companies_data: List[Dict[str, Any]]) -> str:
        """Craft a summary response in the same language the user spoke."""

        user_lang = self._get_message_language(history)

        # Helper text selection
        def t(ru: str, en: str, kk: str) -> str:
            if user_lang.startswith("en"):
                return en
            if user_lang.startswith("kk"):
                return kk
            return ru  # default Russian

        if not companies_data:
            return t(
                ru="–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∫–æ–º–ø–∞–Ω–∏–π. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –∫—Ä–∏—Ç–µ—Ä–∏–∏ –ø–æ–∏—Å–∫–∞.",
                en="Unfortunately, no matching companies were found for your request. Please try different criteria.",
                kk="”®–∫—ñ–Ω—ñ—à–∫–µ –æ—Ä–∞–π, —Å—ñ–∑–¥—ñ“£ —Å“±—Ä–∞–Ω—ã—Å—ã“£—ã–∑ –±–æ–π—ã–Ω—à–∞ —Å”ô–π–∫–µ—Å –∫–æ–º–ø–∞–Ω–∏—è–ª–∞—Ä —Ç–∞–±—ã–ª–º–∞–¥—ã. –ë–∞—Å“õ–∞ —Å“Ø–∑–≥—ñ–ª–µ—Ä–¥—ñ “õ–æ–ª–¥–∞–Ω—ã–ø –∫”©—Ä—ñ“£—ñ–∑."
            )

        parts: list[str] = []

        count = len(companies_data)
        # Opening sentence
        if user_lang.startswith("en"):
            opening = f"Great news! I found information on {count} compan{'y' if count==1 else 'ies'}:"
        elif user_lang.startswith("kk"):
            opening = f"–¢–∞–º–∞—à–∞ –∂–∞“£–∞–ª—ã“õ! –ú–µ–Ω {count} –∫–æ–º–ø–∞–Ω–∏—è —Ç—É—Ä–∞–ª—ã –∞“õ–ø–∞—Ä–∞—Ç —Ç–∞–ø—Ç—ã–º:"
        else:  # Russian
            if count == 1:
                opening = f"–û—Ç–ª–∏—á–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏! –Ø –Ω–∞—à–µ–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ {count} –∫–æ–º–ø–∞–Ω–∏–∏:"
            elif 2 <= count <= 4:
                opening = f"–û—Ç–ª–∏—á–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏! –Ø –Ω–∞—à–µ–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ {count} –∫–æ–º–ø–∞–Ω–∏—è—Ö:"
            else:
                opening = f"–û—Ç–ª–∏—á–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏! –Ø –Ω–∞—à–µ–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ {count} –∫–æ–º–ø–∞–Ω–∏—è—Ö:"

        parts.append(opening)
        parts.append("")

        # Loop companies
        for comp in companies_data:
            name = comp.get("name", "Unknown company")
            bin_num = comp.get("bin", "N/A")
            activity = comp.get("activity", t("–î–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–µ —É–∫–∞–∑–∞–Ω–∞", "Activity not specified", "“ö—ã–∑–º–µ—Ç—ñ –∫”©—Ä—Å–µ—Ç—ñ–ª–º–µ–≥–µ–Ω"))
            size = comp.get("size") or t("–†–∞–∑–º–µ—Ä –Ω–µ —É–∫–∞–∑–∞–Ω", "Size not specified", "”®–ª—à–µ–º—ñ –∫”©—Ä—Å–µ—Ç—ñ–ª–º–µ–≥–µ–Ω")

            if user_lang.startswith("en"):
                entry = (
                    f"‚Ä¢ **{name}**\n"
                    f"  - BIN: {bin_num}\n"
                    f"  - Activity: {activity}\n"
                    f"  - Size: {size}"
                )
            elif user_lang.startswith("kk"):
                entry = (
                    f"‚Ä¢ **{name}**\n"
                    f"  - –ë–°–ù: {bin_num}\n"
                    f"  - “ö—ã–∑–º–µ—Ç—ñ: {activity}\n"
                    f"  - ”®–ª—à–µ–º—ñ: {size}"
                )
            else:  # Russian
                entry = (
                    f"‚Ä¢ **{name}**\n"
                    f"  - –ë–ò–ù: {bin_num}\n"
                    f"  - –î–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {activity}\n"
                    f"  - –†–∞–∑–º–µ—Ä: {size}"
                )

            locality = comp.get("locality") or comp.get("city")
            if locality:
                if user_lang.startswith("en"):
                    entry += f"\n  - Location: {locality}"
                elif user_lang.startswith("kk"):
                    entry += f"\n  - –û—Ä–Ω–∞–ª–∞—Å“õ–∞–Ω –∂–µ—Ä—ñ: {locality}"
                else:
                    entry += f"\n  - –ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ: {locality}"

            annual_tax = comp.get("annual_tax_paid")
            if annual_tax is not None:
                if user_lang.startswith("en"):
                    entry += f"\n  - Taxes paid (last year): {annual_tax:,.0f} ‚Ç∏"
                elif user_lang.startswith("kk"):
                    entry += f"\n  - –¢”©–ª–µ–Ω–≥–µ–Ω —Å–∞–ª—ã“õ (—Å–æ“£“ì—ã –∂—ã–ª): {annual_tax:,.0f} ‚Ç∏"
                else:
                    entry += f"\n  - –£–ø–ª–∞—á–µ–Ω–æ –Ω–∞–ª–æ–≥–æ–≤ (–ø–æ—Å–ª–µ–¥–Ω–∏–π –≥–æ–¥): {annual_tax:,.0f} ‚Ç∏"

            parts.append(entry)

        parts.append("")

        closing = t(
            ru="–ü–æ—Ç—Ä—è—Å–∞—é—â–∞—è —Ä–∞–±–æ—Ç–∞! –£ –≤–∞—Å –µ—Å—Ç—å –±–æ–ª—å—à–æ–π –≤—ã–±–æ—Ä –¥–ª—è –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–∞. –ï—Å–ª–∏ –µ—Å—Ç—å —á—Ç–æ-—Ç–æ –µ—â–µ, —á–µ–º —è –º–æ–≥—É –ø–æ–º–æ—á—å, –¥–∞–π—Ç–µ –∑–Ω–∞—Ç—å!",
            en="Excellent! You now have a great list of potential partners. Let me know if there's anything else I can help with!",
            kk="–¢–∞–º–∞—à–∞! –´“õ—Ç–∏–º–∞–ª —Å–µ—Ä—ñ–∫—Ç–µ—Å—Ç–µ—Ä–¥—ñ“£ –∂–∞“õ—Å—ã —Ç—ñ–∑—ñ–º—ñ –±–∞—Ä. –¢–∞“ì—ã –∫”©–º–µ–∫ –∫–µ—Ä–µ–∫ –±–æ–ª—Å–∞, –∞–π—Ç—ã“£—ã–∑!"
        )
        parts.append(closing)

        return "\n".join(parts)


    def handle_conversation_turn(
        self,
        user_input: str,
        history: List[Dict[str, str]],
        db: Session,
        conversation_id: Optional[str] = None # Added for persistence
    ) -> Dict[str, Any]:
        """
        Main logic for handling a single turn in a conversation.
        - Parses intent
        - Searches database
        - Formulates a response
        """
        print(f"üîÑ [SERVICE] Handling conversation turn for user input: {user_input[:100]}...")

        # Initialize default response values
        companies_data = []
        final_message = "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–∞—à –∑–∞–ø—Ä–æ—Å..."

        try:
            # 1. Get canonical location
            canonical_location = get_canonical_location_from_text(user_input)

            # 2. Append user message to history *before* parsing intent
            history.append({"role": "user", "content": user_input})

            # 3. Parse intent from the full history
            parsed_intent = self._parse_user_intent_with_history(history)
            
            # 4. Override location if canonical version was found
            if canonical_location:
                print(f"üìç [SERVICE] Overriding intent location with canonical name: '{canonical_location}'")
                parsed_intent['location'] = canonical_location
            
            intent = parsed_intent.get("intent")
            location = parsed_intent.get("location")
            activity_keywords = parsed_intent.get("activity_keywords")
            page = parsed_intent.get("page_number", 1)
            
            print(f"üéØ Intent parsed: {intent}, location: {location}, keywords: {activity_keywords}")
            
            # Calculate search parameters
            raw_quantity_from_ai = parsed_intent.get("quantity")
            default_limit = 10
            max_limit = 200

            # --- >>> START OF IMPROVED QUANTITY BLOCK <<< ---
            final_quantity = None

            # 1) Try to use the value provided by the model
            if raw_quantity_from_ai is not None:
                try:
                    final_quantity = int(raw_quantity_from_ai)
                except (ValueError, TypeError):
                    pass  # We'll try other heuristics below

            # 2) If the model didn't give us a useful number (None or default 10),
            #    attempt to extract a number directly from the user's last message.
            if final_quantity is None or final_quantity == default_limit:
                print("ü§î AI returned default/no quantity. Checking user_input for a number...")
                user_text = history[-1].get("content", "")
                match = re.search(r'\b(\d{1,3})\b', user_text)  # look for 1-3 digit number
                if match:
                    try:
                        num_from_text = int(match.group(1))
                        if num_from_text > 0:
                            print(f"‚úÖ Found quantity '{num_from_text}' directly in user text. Using it.")
                            final_quantity = num_from_text
                    except (ValueError, TypeError):
                        pass

            # 3) Fallback to default if still unresolved
            if final_quantity is None:
                final_quantity = default_limit

            # Apply global limits
            search_limit = min(final_quantity, max_limit)
            # --- >>> END OF IMPROVED QUANTITY BLOCK <<< ---

            offset = (page - 1) * search_limit
            print(f"üìä Final search params: limit={search_limit}, offset={offset}, page={page}")

            # --- DEBUG: Add detailed pagination debugging ---
            print("üî¢ [PAGINATION] Detailed calculation:")
            print(f"   Raw quantity from OpenAI: {raw_quantity_from_ai}")
            print(f"   Final quantity selected: {final_quantity}")
            print(f"   Page number from OpenAI: {page}")
            print(f"   Calculated offset: {offset} = ({page} - 1) * {search_limit}")
            print(f"   Final query will be: LIMIT {search_limit} OFFSET {offset}")
            
            final_message = parsed_intent.get("preliminary_response", "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–∞—à –∑–∞–ø—Ä–æ—Å...")

            # 3. If intent is to find companies, fetch data from DB
            if intent == "find_companies" and location:
                print(f"üè¢ Searching for companies in {location}...")
                print(f"üîç [DATABASE] Query parameters:")
                print(f"   location: {location}")
                print(f"   activity_keywords: {activity_keywords}")
                print(f"   limit: {search_limit}")
                print(f"   offset: {offset}")
                
                company_service = CompanyService(db)
                db_companies = company_service.search_companies(
                    location=location,
                    activity_keywords=activity_keywords,
                    limit=search_limit,
                    offset=offset
                )
                
                print(f"üìà Found {len(db_companies) if db_companies else 0} companies in database")
                print(f"üîç [DATABASE] Query returned {len(db_companies) if db_companies else 0} results")
                
                # --- DEBUG: Log first few company names for verification ---
                if db_companies:
                    print(f"üè¢ [DATABASE] First few companies returned:")
                    for i, company in enumerate(db_companies[:3]):
                        print(f"   {i+1}. {company.get('name', 'N/A')} (ID: {company.get('id', 'N/A')[:8]}...)")
                    if len(db_companies) > 3:
                        print(f"   ... and {len(db_companies) - 3} more companies")
                else:
                    print(f"‚ö†Ô∏è [DATABASE] No companies returned - this might indicate:")
                    print(f"   - End of results reached (no more companies match criteria)")
                    print(f"   - Query parameters don't match any records")
                    print(f"   - Database connectivity issue")
                
                if db_companies:
                    # 4. Enrich DB data with web search results
                    print("üåê Enriching companies with web search...")
                    enriched_companies = self._enrich_companies_with_web_search(db_companies)
                    companies_data = enriched_companies
                    
                    # 5. Generate a final summary response with all data
                    print("‚úçÔ∏è Generating summary response...")
                    final_message = self._generate_summary_response(history, companies_data)
                else:
                    final_message = f"–Ø –∏—Å–∫–∞–ª –∫–æ–º–ø–∞–Ω–∏–∏ –≤ {location}, –Ω–æ –Ω–µ —Å–º–æ–≥ –Ω–∞–π—Ç–∏ –±–æ–ª—å—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É. –ú–æ–∂–µ—Ç, –ø–æ–ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–æ–π –≥–æ—Ä–æ–¥ –∏–ª–∏ –∏–∑–º–µ–Ω–∏–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞?"
            
            elif intent == "find_companies" and not location:
                final_message = "–ß—Ç–æ–±—ã –Ω–∞–π—Ç–∏ –∫–æ–º–ø–∞–Ω–∏–∏, –º–Ω–µ –Ω—É–∂–Ω–æ –∑–Ω–∞—Ç—å, –≤ –∫–∞–∫–æ–º –≥–æ—Ä–æ–¥–µ –∏–ª–∏ —Ä–µ–≥–∏–æ–Ω–µ –≤—ã —Ö–æ—Ç–∏—Ç–µ –∏—Å–∫–∞—Ç—å. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ."

        except Exception as e:
            print(f"‚ùå Critical error during conversation processing: {e}")
            # Roll back in case the session is in a failed state so that outer callers can continue safely
            try:
                if db:
                    db.rollback()
            except Exception as rollback_error:
                print(f"‚ö†Ô∏è Could not rollback session after critical error: {rollback_error}")
            traceback.print_exc()
            final_message = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–∞—à –≤–æ–ø—Ä–æ—Å."

        # CRITICAL: Always append the final AI response to history
        history.append({"role": "assistant", "content": final_message})
        print(f"‚úÖ Added AI response, final history length: {len(history)}")

        # 7. Save updated history to the database (if implementation exists)
        # if conversation_id and db: ...

        # 8. Prepare the final response object
        companies_found_count = len(companies_data)
        has_more = companies_found_count >= search_limit
        
        return {
            'message': final_message,
            'companies': companies_data,
            'updated_history': history,
            'intent': parsed_intent.get("intent") if 'parsed_intent' in locals() else 'unclear',
            'location_detected': parsed_intent.get("location") if 'parsed_intent' in locals() else None,
            'activity_keywords_detected': parsed_intent.get("activity_keywords") if 'parsed_intent' in locals() else None,
            'quantity_detected': parsed_intent.get("quantity") if 'parsed_intent' in locals() else None,
            'page_number': parsed_intent.get("page_number", 1) if 'parsed_intent' in locals() else 1,
            'companies_found': companies_found_count,
            'has_more_companies': has_more,
            'reasoning': parsed_intent.get('reasoning') if 'parsed_intent' in locals() else None,
            # 'conversation_id': conversation_id
        }

    def handle_conversation_with_assistant_fallback(
        self,
        user_input: str,
        history: List[Dict[str, str]],
        db: Session,
        conversation_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Handle conversation with assistant fallback.
        If the assistant fails, fallback to the traditional OpenAI service.
        This provides the best of both worlds - enhanced context with reliability.
        """
        try:
            # First, try using the enhanced assistant
            print("ü§ñ [SERVICE] Attempting to use enhanced assistant...")
            from .assistant_creator import handle_conversation_with_context
            
            # TODO: This call has incorrect arguments. `handle_conversation_with_context` expects a `user` object.
            response_data = handle_conversation_with_context(
                user_input=user_input,
                conversation_history=history,
                db=db
            )
            
            print("‚úÖ [SERVICE] Enhanced assistant succeeded")
            return response_data
            
        except Exception as assistant_error:
            print(f"‚ö†Ô∏è [SERVICE] Enhanced assistant failed: {str(assistant_error)}")
            print("üîÑ [SERVICE] Falling back to traditional OpenAI service...")
            
            try:
                # Fallback to traditional service
                response_data = self.handle_conversation_turn(
                    user_input=user_input,
                    history=history,
                    db=db,
                    conversation_id=conversation_id
                )
                
                # Add a note about fallback
                original_message = response_data.get('message', '')
                response_data['message'] = f"{original_message}\n\n(–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –±–∞–∑–æ–≤–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞)"
                
                print("‚úÖ [SERVICE] Traditional service fallback succeeded")
                return response_data
                
            except Exception as fallback_error:
                print(f"‚ùå [SERVICE] Both assistant and traditional service failed")
                print(f"   Assistant error: {str(assistant_error)}")
                print(f"   Fallback error: {str(fallback_error)}")
                
                # Last resort: preserve history and return error
                error_history = history.copy()
                error_history.append({"role": "user", "content": user_input})
                error_history.append({
                    "role": "assistant", 
                    "content": "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –æ–±–µ–∏—Ö —Å–∏—Å—Ç–µ–º–∞—Ö. –í–∞—à–∞ –∏—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å."
                })
                
                return {
                    'message': "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –æ–±–µ–∏—Ö —Å–∏—Å—Ç–µ–º–∞—Ö. –í–∞—à–∞ –∏—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å.",
                    'companies': [],
                    'updated_history': error_history,
                    'intent': "error",
                    'location_detected': None,
                    'activity_keywords': None,
                    'quantity_requested': None,
                    'companies_found': 0,
                    'has_more_companies': False,
                    'reasoning': f"Both systems failed. Assistant: {str(assistant_error)}, Fallback: {str(fallback_error)}"
                }


# Global service instance
ai_service = OpenAIService()